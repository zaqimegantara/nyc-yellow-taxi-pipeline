

# NYC Taxi Trip Pipeline: From Ingestion to Dashboard

## Introduction

This project showcases an **endâ€‘toâ€‘end data engineering pipeline** built to process NYC Taxi Trip data â€” starting from raw files, moving through cloud storage and a data warehouse, applying dbt transformations, and finally visualizing insights in Power BI.

The goal is to demonstrate how different tools and services work together in a seamless workflow:

* Ingestion â” Azure Blob Storage
* Modeling â” Snowflake + dbt
* Visualization â” Power BI Dashboard

---

## What This Project Covers

- **Ingestion**: Uploading raw NYC Taxi Trip Parquet files into Azure Blob Storage.
- **Loading**: Creating Snowflake stages and loading raw files into the `raw` schema.
- **Modeling**: Using dbt to transform and clean data into analytics-ready tables.
- **Visualization**: Final metrics and KPIs built in Power BI from the modeled data.
- **Future**: Orchestration and scheduling with Apache Airflow.

---

## Architecture Diagram

```mermaid
flowchart LR
    A["Raw Parquet 
    Azure Blob"] --> B["Snowflake
    RAW Schema"]
    B --> C["dbt Models
    (STG -> INT -> FACT/DIM)"]
    C --> D["Power BI Dashboard"]
    C -.-> E["Apache Airflow\nFuture Orchestration"]

```



---

## Directory Structure

```
nyc-taxi-pipeline/
â”œâ”€ ğŸ“ dags/                # Apache Airflow (Future)
â”œâ”€ ğŸ“ dashboard/           # Power BI .pbix files
â”œâ”€ ğŸ“ data/                # Source data files
â”œâ”€ ğŸ“ dbt_nyc_yellow/      # dbt project directory
â”œâ”€ ğŸ“ docker/              # Docker files
â”œâ”€ ğŸ“ scripts/             # Scripts for Azure Blob uploading
â”œâ”€ ğŸ“ logs/                # Logs for dbt, airflow
â”œâ”€ .gitignore              # Excluding secrets
â”œâ”€ requirements.txt        # Python dependencies
â”œâ”€ README.md               # Project documentation
```

---

## Technologies

* **Python 3.9+**
* **Azure Blob Storage** (data lake for raw files)
* **Snowflake** (data warehouse for raw and modeled data)
* **dbt** (data modeling and testing framework)
* **Power BI** (dashboard and analytics)
* **Apache Airflow** (future workflow orchestration)

---

## Getting Started

### Prerequisites

* Azure Blob Storage account
* Snowflake account
* Python 3.9+
* dbt-core and dbt-snowflake installed
* Power BI for viewing the `.pbix` files
* `.env` files configured for Azure and Snowflake connections

---

### Install Dependencies

```bash
pip install -r requirements.txt
```

---

### Usage

#### 1ï¸âƒ£ Ingest

Upload raw files (`yellow_tripdata_2025-01.parquet`) to Azure Blob:

```bash
python scripts/upload_to_blob.py
```

#### 2ï¸âƒ£ Load

Load raw files from Azure Blob into Snowflakeâ€™s `raw` schema.

#### 3ï¸âƒ£ Model

Run dbt transformations:

```bash
cd dbt_nyc_yellow
dbt run
```

#### 4ï¸âƒ£ Visualize

Open the `.pbix` files in `dashboard/` to explore KPIs, trips, revenues, and more.

---

## Final Outcome

An endâ€‘toâ€‘end analytics solution where:
âœ… Data moves reliably from Azure Blob â” Snowflake â” dbt â” Power BI.
âœ… You can clearly trace every step from raw files â” clean analytics tables â” final dashboards.

---

## Final Dashboard

The results of this endâ€‘toâ€‘end pipeline are visualized in a Power BI Dashboard.  
It provides actionable insights and metrics for stakeholders, making it easy to understand taxi trip patterns, revenue trends, and operational KPIs.

![Power BI Dashboard](dashboard/images.png)


> ğŸ’¡ **Highlights:**  
> - **3.48M Total Trips** recorded within the selected time range  
> - **$89.01M Total Revenue**, giving a quick snapshot of earnings  
> - **$24.13K Average Fare** and **$2.01K Average Tip** per trip  
> - **Detailed Daily Trends**: Enables quick identification of revenue peaks and dips  
> - **Breakdown by Payment Method** (Credit Card, Cash, Dispute, No Charge, Unknown), allowing deep dives into customer behavior  
> - **Average Trip Distance vs Fare** for deeper operational insights


## Created By

**Rizky Zaqi Megantara**
[LinkedIn](https://www.linkedin.com/in/zaqi-megantara-4989ab2a2/) | [GitHub](https://github.com/zaqimegantara)

---

## Final Notes

With this project, you have a solid, reproducible example of **modern data engineering practices**:

* âœ… Clear data flow from ingestion â” warehouse â” analytics
* âœ… Fully versionâ€‘controlled dbt transformations
* âœ… Interactive dashboards for stakeholders
* â³ Scalability builtâ€‘in for future workflow automation

> Thanks for checking out this project!
> If you found it helpful, â­ï¸ the repo and feel free to contribute.

---

